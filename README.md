# TaxiProblems リポジトリ

Taxi問題のシミュレーションを行うプログラム集
ローカルでディレクトリを複製しては，アルゴリズムなどを書き換えるようにして作業しており，そのままリポジトリをリモートに上げたので重複するファイルが非常に多くなっています(もう少しちゃんと管理すればよかった...)

## 各ディレクトリ

- `Draw`: 実験結果(最適行動選択率)の描画用
- `TaxiProblem`: ε-greedy法、中でさらにε固定とε更新のもので分かれています
- `TaxiProblem_softmax`: Softmax法(パラメータチューニングうまくいかず)
- `TaxiProblem_SpeeyQ`: SpeedyQを実装、比較しようとしたが結局使っていない
- `TaxiProblemwithLA`: (βタイプ)学習オートマトンを用いた手法、内部にベイズ推定器やβタイプ学習オートマトンを実装したソースコードを含みます

## 使い方
基本的にはコード読めばわかりますが
1. Const/constant.pyのパラメータ値を編集
2. taxiproblem.py(mainファイル)を実行
3. glaphs,probabilitiesフォルダに結果が出てくるのでそれを参照する(パラメータを変えるとファイル名変わる)
4. 各手法との比較などしたい場合はprobabilitiesのファイルをDrawに持ってきてそれを使って描画
すればできます

## 手法について
論文(pdf)も上げたので，研究の詳細はそちらをご覧ください

## 研究について
これから私の研究を引き継ぐ人が出るかもしれないので，改良点や考慮すべき点を挙げておくと
- β-LAを使うと，環境が大きいほど多くの計算資源を要するので(環境の状態 × 行動数 × ベイズ推定器の状態数)，もう少し効率の良いやり方を考える
- モデルベース学習なので，調整するパラメータを減らせるようにしたい(モデルフリー性)
- 単純に時間がかかってしまうので並列処理を入れれるとよい
- 査読のある学会への発表を目指すなら, 以下の手法との比較したい
  - SpeedyQ : https://proceedings.neurips.cc/paper/2011/hash/ab1a4d0dd4d48a2ba1077c4494791306-Abstract.html
  - UCBとQ学習を組み合わせた手法 : https://arxiv.org/abs/1901.09311
- 私も先生も知らなかったですが, Bayesian RL というものもあるらしい．こっちはモデルフリーなのでよく比較してみるとよいかも．
https://arxiv.org/abs/1609.04436

何かあれば連絡ください
